import os
# ==========================================
# å…³é”®ä¿®å¤ 1: ç¦ç”¨ NVML ä»¥è§£å†³ nvml error (3)
# å¿…é¡»åœ¨å¯¼å…¥ nvidia.dali ä¹‹å‰è®¾ç½®
# ==========================================
os.environ["DALI_DISABLE_NVML"] = "1"

import time
import torch
import numpy as np
from PIL import Image
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# å°è¯•å¯¼å…¥ DALI
try:
    import nvidia.dali.fn as fn
    import nvidia.dali.types as types
    from nvidia.dali import pipeline_def
    from nvidia.dali.plugin.pytorch import DALIGenericIterator
    DALI_AVAILABLE = True
except ImportError:
    DALI_AVAILABLE = False
    print("Warning: NVIDIA DALI åº“æœªå®‰è£…ã€‚")

# ================= é…ç½®å‚æ•° =================
BATCH_SIZE = 128
NUM_WORKERS = 4
IMAGE_SIZE = 224
NUM_IMAGES = 2000
DATA_DIR = "./dummy_data_benchmark"
EPOCHS = 2

# ================= 1. æ•°æ®å‡†å¤‡ (è‡ªåŠ¨ç”Ÿæˆ) =================
def create_dummy_data(root_dir, num_images):
    if os.path.exists(root_dir):
        return
    print(f"æ­£åœ¨ç”Ÿæˆ {num_images} å¼ æµ‹è¯•å›¾ç‰‡åˆ° {root_dir} ...")
    os.makedirs(os.path.join(root_dir, "class_a"), exist_ok=True)
    for i in range(num_images):
        img = np.random.randint(0, 255, (300, 300, 3), dtype=np.uint8)
        Image.fromarray(img).save(os.path.join(root_dir, "class_a", f"{i}.jpg"))
    print("æ•°æ®ç”Ÿæˆå®Œæ¯•ã€‚")

# ================= 2. PyTorch DataLoader =================
def get_torch_loader(root_dir, mode='train'):
    if mode == 'train':
        transform = transforms.Compose([
            transforms.RandomResizedCrop(IMAGE_SIZE),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ])
        shuffle = True
    else:
        transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(IMAGE_SIZE),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ])
        shuffle = False

    dataset = datasets.ImageFolder(root_dir, transform=transform)
    return DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=shuffle, 
                      num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)

# ================= 3. NVIDIA DALI Pipeline (ç°ä»£å‡½æ•°å¼ API) =================
# å…³é”®ä¿®å¤ 2: ä½¿ç”¨ @pipeline_def å’Œ fn.* æ›¿ä»£æ—§çš„ class Pipeline å’Œ ops.*
@pipeline_def(batch_size=BATCH_SIZE, num_threads=NUM_WORKERS, device_id=0)
def create_dali_pipeline(data_dir, mode='train'):
    # è¯»å–æ–‡ä»¶
    jpegs, labels = fn.readers.file(file_root=data_dir, 
                                    random_shuffle=(mode == 'train'), 
                                    name="Reader")
    
    # è§£ç  (æ··åˆè®¾å¤‡: CPUè¯»å– -> GPUè§£ç )
    images = fn.decoders.image(jpegs, device="mixed", output_type=types.RGB)
    
    if mode == 'train':
        # è®­ç»ƒå¢å¼ºï¼šéšæœºè£å‰ª + ç¿»è½¬ + å½’ä¸€åŒ–
        images = fn.random_resized_crop(images, size=IMAGE_SIZE, device="gpu")
        mirror = fn.random.coin_flip(probability=0.5) # æ›¿ä»£äº†æ—§çš„ ops.CoinFlip
    else:
        # æ¨ç†å¢å¼ºï¼šResize + CenterCrop (é€šè¿‡ crop_mirror_normalize å®ç°)
        images = fn.resize(images, device="gpu", resize_shorter=256)
        mirror = False
        
    # å½’ä¸€åŒ– + æ ¼å¼è½¬æ¢ (HWC -> CHW)
    # æ³¨æ„ï¼šéªŒè¯é›†å¦‚æœéœ€è¦ CenterCropï¼Œé€šå¸¸åœ¨è¿™é‡Œè®¾ç½® crop å‚æ•°ï¼Œæˆ–è€…åœ¨ resize ååŠ  fn.crop
    # è¿™é‡Œä¸ºäº†å¯¹é½ PyTorch çš„ç®€å•é€»è¾‘ï¼Œç›´æ¥ç”¨ CropMirrorNormalize åšæœ€åçš„å¤„ç†
    images = fn.crop_mirror_normalize(images, 
                                      device="gpu",
                                      dtype=types.FLOAT,
                                      output_layout=types.NCHW,
                                      crop=(IMAGE_SIZE, IMAGE_SIZE), # å¼ºåˆ¶è£å‰ªåˆ°ç›®æ ‡å°ºå¯¸
                                      mean=[0.485 * 255, 0.456 * 255, 0.406 * 255],
                                      std=[0.229 * 255, 0.224 * 255, 0.225 * 255],
                                      mirror=mirror)
    
    return images, labels

def get_dali_iter(data_dir, mode='train'):
    pipe = create_dali_pipeline(data_dir=data_dir, mode=mode)
    pipe.build()
    # è·å– epoch å¤§å°
    size = pipe.epoch_size("Reader")
    dali_iter = DALIGenericIterator(pipe, ["data", "label"], reader_name="Reader", auto_reset=True)
    return dali_iter, size

# ================= 4. æµ‹è¯•å‡½æ•° =================
def benchmark(loader, num_images, name):
    print(f"--- å¼€å§‹æµ‹è¯•: {name} ---")
    
    # é¢„çƒ­
    print("é¢„çƒ­ä¸­...")
    try:
        for _ in loader: break
    except StopIteration: pass
    
    if hasattr(loader, "reset"): loader.reset() # DALI é‡ç½®
    
    # è®¡æ—¶
    print("æ­£å¼è®¡æ—¶å¼€å§‹...")
    torch.cuda.synchronize()
    start_time = time.time()
    
    count = 0
    for _ in range(EPOCHS):
        for i, data in enumerate(loader):
            if isinstance(loader, DataLoader):
                images = data[0].cuda(non_blocking=True)
            else:
                # DALI
                images = data[0]["data"]
            count += images.shape[0]
            
    torch.cuda.synchronize()
    end_time = time.time()
    
    throughput = count / (end_time - start_time)
    print(f"[{name}] ååé‡: {throughput:.2f} images/sec")
    return throughput

# ================= ä¸»ç¨‹åº =================
if __name__ == "__main__":
    if not torch.cuda.is_available():
        print("é”™è¯¯: å¿…é¡»æœ‰ NVIDIA GPU æ‰èƒ½è¿è¡Œæ­¤è„šæœ¬ã€‚")
        exit(1)

    create_dummy_data(DATA_DIR, NUM_IMAGES)
    
    # 1. PyTorch Train
    ts = benchmark(get_torch_loader(DATA_DIR, 'train'), NUM_IMAGES, "PyTorch Train")
    
    # 2. DALI Train
    if DALI_AVAILABLE:
        dl, size = get_dali_iter(DATA_DIR, 'train')
        ds = benchmark(dl, size, "DALI Train")
        print(f"ğŸš€ è®­ç»ƒåŠ é€Ÿæ¯”: {ds / ts:.2f}x")

    print("-" * 30)

    # 3. PyTorch Eval
    ts_eval = benchmark(get_torch_loader(DATA_DIR, 'eval'), NUM_IMAGES, "PyTorch Eval")
    
    # 4. DALI Eval
    if DALI_AVAILABLE:
        dl_eval, size = get_dali_iter(DATA_DIR, 'eval')
        ds_eval = benchmark(dl_eval, size, "DALI Eval")
        print(f"ğŸš€ æ¨ç†åŠ é€Ÿæ¯”: {ds_eval / ts_eval:.2f}x")
